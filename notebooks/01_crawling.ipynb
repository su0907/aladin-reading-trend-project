{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kioRvJs6lC3n"
      },
      "outputs": [],
      "source": [
        "# Step 0: 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 작업 디렉토리 설정\n",
        "import os\n",
        "project_path = '/content/drive/MyDrive/aladin-project'\n",
        "\n",
        "# 폴더가 없으면 생성\n",
        "os.makedirs(project_path, exist_ok=True)\n",
        "os.makedirs(f'{project_path}/data/raw', exist_ok=True)\n",
        "\n",
        "%cd {project_path}\n",
        "print(f\"현재 작업 디렉토리: {os.getcwd()}\")\n",
        "\n",
        "# 필요 라이브러리\n",
        "import re\n",
        "import time, datetime, ssl\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from itertools import count\n",
        "from bs4 import BeautifulSoup\n",
        "from random import uniform\n",
        "\n",
        "class AladinBestSeller():\n",
        "    myencoding = 'utf-8'\n",
        "\n",
        "    def getSoup(self):\n",
        "        if self.soup == None:\n",
        "            return None\n",
        "        else:\n",
        "            return BeautifulSoup(self.soup, 'html.parser')\n",
        "\n",
        "    def get_request_url(self):\n",
        "        request = urllib.request.Request(self.url)\n",
        "        try:\n",
        "            context = ssl._create_unverified_context()\n",
        "            response = urllib.request.urlopen(request, context=context)\n",
        "            if response.getcode() == 200:\n",
        "                return response.read().decode(self.myencoding)\n",
        "        except Exception as err:\n",
        "            print(err)\n",
        "            now = datetime.datetime.now()\n",
        "            msg = '[%s] error for url %s' % (now, self.url)\n",
        "            print(msg)\n",
        "            return None\n",
        "\n",
        "    def save2Csv(self, result):\n",
        "        data = pd.DataFrame(result, columns=self.mycolumns)\n",
        "        # 구글 드라이브 경로에 저장\n",
        "        save_path = f'data/raw/{self.siteName}.csv'\n",
        "        data.to_csv(save_path, encoding='utf-8-sig', index=True)\n",
        "        print(f\"✅ 파일 저장 완료: {save_path}\")\n",
        "\n",
        "    def __init__(self, siteName, url):\n",
        "        self.siteName = siteName\n",
        "        self.url = url\n",
        "        self.mycolumns = ['year', 'month', 'rank', 'category', 'title', 'price', 'star_score', 'item_id']\n",
        "        self.soup = self.get_request_url()\n",
        "\n",
        "####################################################\n",
        "siteName = 'aladin'\n",
        "base_url = 'https://www.aladin.co.kr/shop/common/wbest.aspx'\n",
        "####################################################\n",
        "\n",
        "def getData():\n",
        "    savedData = []\n",
        "    for year in range(2020, 2026):\n",
        "        last_month = 9 if year == 2025 else 12\n",
        "        for month in range(1, last_month + 1):\n",
        "            url = base_url\n",
        "            url += '?BranchType=1&CID=0&Year=' + str(year)\n",
        "            url += '&Month=' + str(month)\n",
        "            url += '&Week=1&BestType=MonthlyBest&SearchSubBarcode='\n",
        "            print(url)\n",
        "\n",
        "            aladin = AladinBestSeller(siteName, url)\n",
        "            soup = aladin.getSoup()\n",
        "\n",
        "            if soup is None:\n",
        "                break\n",
        "\n",
        "            for rank, item in enumerate(soup.select(\"div.ss_book_box\"), start=1):\n",
        "                try:\n",
        "                    catrgory_tag = item.select_one(\"span.tit_catrgory\")\n",
        "                    catrgory = catrgory_tag.get_text(strip=True).strip('[]') if catrgory_tag else \"N/A\"\n",
        "\n",
        "                    title_tag = item.select_one(\"a.bo3\")\n",
        "                    title = title_tag.get_text(strip=True) if title_tag else \"N/A\"\n",
        "\n",
        "                    item_id = \"N/A\"\n",
        "                    if title_tag and title_tag.has_attr('href'):\n",
        "                        match = re.search(r'ItemId=(\\d+)', title_tag['href'])\n",
        "                        if match:\n",
        "                            item_id = match.group(1)\n",
        "\n",
        "                    price_tag = item.select_one(\"span.ss_p2\")\n",
        "                    price_text = price_tag.get_text(strip=True).split('원')[0] if price_tag else \"0\"\n",
        "                    price = int(price_text.replace(\",\", \"\"))\n",
        "\n",
        "                    star_score_tag = item.select_one(\"span.star_score\")\n",
        "                    star_score = float(star_score_tag.get_text(strip=True)) if star_score_tag else 0.0\n",
        "\n",
        "                    savedData.append([year, month, rank, catrgory, title, price, star_score, item_id])\n",
        "                except Exception as err:\n",
        "                    print(err)\n",
        "                    continue\n",
        "\n",
        "            time.sleep(uniform(1, 2))\n",
        "\n",
        "    aladin.save2Csv(savedData)\n",
        "    print('=' * 50)\n",
        "    print(f\"총 {len(savedData)}개 데이터 수집 완료\")\n",
        "    return len(savedData)\n",
        "\n",
        "####################################################\n",
        "print(siteName + ' 베스트셀러 크롤링 시작')\n",
        "total_count = getData()\n",
        "print(siteName + ' 베스트셀러 크롤링 끝')\n",
        "print(f\"data/raw/aladin.csv 파일이 구글 드라이브에 저장되었습니다.\")"
      ]
    }
  ]
}