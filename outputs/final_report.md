# 알라딘 월간 베스트셀러 데이터 분석 프로젝트

**기간:** 2020년 1월 ~ 2025년 11월 (71개월)  
**분석 대상:** 알라딘 월간 베스트셀러 TOP 50  
**GitHub:** https://github.com/username/aladin-project

---

# 1. 프로젝트 개요

## 1.1 목적

본 프로젝트는 2020~2025년 알라딘 월간 베스트셀러 데이터를 크롤링 및 분석하여 독서 트렌드 변화를 파악하는 것을 목표로 합니다.

## 1.2 기술 스택

- **언어:** Python 3.10+
- **크롤링:** BeautifulSoup4, urllib
- **데이터 처리:** Pandas, NumPy
- **시각화:** Matplotlib, Seaborn, Plotly
- **환경:** Google Colab
- **저장/관리:** Google Drive

---

# 2. 데이터 수집

## 2.1 크롤링 대상 및 기간

| 항목 | 내용 |
|------|------|
| **대상 사이트** | 알라딘 (www.aladin.co.kr) |
| **수집 기간** | 2020년 1월 ~ 2025년 11월 (71개월) |
| **수집 범위** | 월간 베스트셀러 TOP 50 |
| **이론적 수집량** | 71개월 × 50개 = 3,550개 |
| **실제 수집량** | 3,539개 (11개 누락) |

## 2.2 1차 크롤링: 월간 베스트셀러 리스트

### 2.2.1 URL 구조 분석

알라딘 월간 베스트셀러 페이지의 URL 구조는 다음과 같습니다:
```
https://www.aladin.co.kr/shop/common/wbest.aspx?BranchType=1&BestType=Month&Year={year}&Month={month}

파라미터:
- BranchType=1: 국내도서
- BestType=Month: 월간 베스트셀러
- Year={year}: 연도 (2020~2025)
- Month={month}: 월 (1~12)
```

### 2.2.2 HTML 선택자 탐색

웹 브라우저의 F12 개발자 도구를 사용하여 HTML 구조를 분석하고, 다음과 같은 CSS Selector를 추출했습니다:

| 데이터 | CSS Selector |
|--------|--------------|
| 도서 컨테이너 | `div.ss_book_box` |
| 제목 | `a.bo3` |
| 저자 | `li.ss_aut a` |
| 카테고리 | `span.tit_category` |
| 가격 | `span.ss_p2 b` |
| 평점 | `span.Ere_fs14.Ere_str` |

### 2.2.3 크롤링 코드 (핵심 로직)

**도서 정보 추출 부분:**
```python
# 도서 정보 추출
items = soup.select("div.ss_book_box")
books = []

for rank, item in enumerate(items, 1):
    try:
        # 제목
        title_tag = item.select_one("a.bo3")
        title = title_tag.text.strip() if title_tag else "N/A"
        
        # 저자
        author_tag = item.select_one("li.ss_aut a")
        author = author_tag.text.strip() if author_tag else "N/A"
        
        # 카테고리
        category_tag = item.select_one("span.tit_category")
        category = category_tag.text.strip() if category_tag else "N/A"
        
        # 가격
        price_tag = item.select_one("span.ss_p2 b")
        price = int(price_tag.text.strip().replace(',', '')) if price_tag else 0
        
        # 평점
        star_tag = item.select_one("span.Ere_fs14.Ere_str")
        star_score = float(star_tag.text.strip()) if star_tag else 0.0
        
        # item_id (도서 고유 ID)
        link_tag = item.select_one("a.bo3")
        item_id = link_tag['href'].split('ItemId=')[1].split('&')[0] if link_tag else "N/A"
        
        books.append({
            'year': year,
            'month': month,
            'rank': rank,
            'title': title,
            'author': author,
            'category': category,
            'price': price,
            'star_score': star_score,
            'item_id': item_id
        })
    except Exception as e:
        print(f"Error at {year}-{month} rank {rank}: {e}")
        continue
```

**전체 기간 크롤링 설정:**
```python
# 전체 기간 크롤링 실행 (2020년 1월 ~ 2025년 11월)
all_books = []
for year in range(2020, 2026):
    for month in range(1, 13):
        if year == 2025 and month > 11:  # 2025년 11월까지만
            break
        
        print(f"Crawling {year}-{month:02d}...")
        books = crawl_bestseller(year, month)
        all_books.extend(books)
        time.sleep(1)  # 서버 부하 방지
```

> **Note:** 전체 코드는 [GitHub Repository](https://github.com/username/aladin-project)에서 확인 가능합니다.

### 2.2.4 수집 결과
```
총 수집: 3,539개 행
예상 수집: 3,550개 행
누락: 11개 (0.3%)

누락 상세:
- 2020년 4월: 1개 누락 (49개 수집)
- 2023년 2~11월: 각 1개씩 누락 (10개월, 각 49개 수집)
```

## 2.3 2차 크롤링: 도서 상세 정보

### 2.3.1 크롤링 목적

1차 크롤링에서는 **포괄적 카테고리**(예: "국내도서")만 수집되었으므로, 도서 상세 페이지에서 **구체적 카테고리**(예: "소설/시/희곡")와 **페이지 수**를 추가로 수집합니다.

### 2.3.2 도서 상세 페이지 구조
```
URL: https://www.aladin.co.kr/shop/wproduct.aspx?ItemId={item_id}

추출 정보:
1. detail_category (상세 카테고리)
   - 선택자: ul.conts_info_list1 li
   - 예시: "국내도서 > 소설/시/희곡 > 한국소설"
   
2. page_count (페이지 수)
   - 선택자: ul.conts_info_list1 li
   - 예시: "368쪽"
```

### 2.3.3 병렬 처리 구현

고유 도서 1,960개의 상세 페이지를 효율적으로 크롤링하기 위해 **ThreadPoolExecutor**를 사용한 병렬 처리를 구현했습니다 (10개 스레드 동시 실행).

> **Note:** 전체 코드는 [GitHub Repository](https://github.com/username/aladin-project)에서 확인 가능합니다.

### 2.3.4 수집 결과
```
고유 도서: 1,960개
수집 성공: 1,958개
수집 실패: 2개

실패 원인: 도서 상세 페이지 삭제 또는 URL 변경
```

## 2.4 크롤링 이슈 및 해결

### 이슈 1: HTML 선택자 오타

**문제:**
- 초기 코드에서 `span.tit_catrgory`로 오타 발생 ("category" 스펠링 오류)
- 모든 도서의 `category` 값이 `None`으로 수집됨

**해결:**
- `span.tit_category`로 수정
- 카테고리 정보 정상 수집 확인

---

### 이슈 2: 50위 도서 크롤링 실패

**문제:**
- BeautifulSoup 파싱 결과 49개만 수집 (50개 예상)
- F12 개발자 도구로 확인 시 50위 도서가 페이지에 존재

**해결 시도:**
1. **Selenium 사용:** Google Colab 환경에서 Chrome Driver 설치 실패
2. **대기 시간 추가:** 여전히 49개만 수집

**최종 결론:**
- 11개 데이터 누락 (전체의 0.3%)
- 분석에 미치는 영향 미미
- 향후 개선 과제로 남김

---

### 이슈 3: 성인 도서 크롤링 제한

**문제:**
- 성인 인증이 필요한 도서는 상세 페이지 접근 불가
- `detail_category` = `None`, `page_count` = `0`으로 수집됨

**영향받은 데이터:**
```
총 21개 고유 도서
베스트셀러 진입 횟수: 22회
```

**해결:**
- 전처리 단계에서 제거 (3.3절 참조)

## 2.5 데이터 저장 구조
```
data/
├── raw/
│   ├── aladin.csv              # 1차 크롤링 결과
│   │   ├── 행 수: 3,539개
│   │   ├── 컬럼: year, month, rank, title, author, 
│   │   │        category, price, star_score, item_id
│   │   └── 인코딩: UTF-8-sig
│   │
│   └── detail_mapping.csv      # 2차 크롤링 결과
│       ├── 행 수: 1,958개 (고유 도서)
│       ├── 컬럼: item_id, detail_category, page_count
│       └── 인코딩: UTF-8-sig
│
└── processed/
    └── aladin_final_cleaned.csv  # 최종 정제 데이터
        ├── 행 수: 3,517개
        ├── 컬럼: year, month, rank, title, author,
        │        category, price, star_score, item_id, page_count
        └── 인코딩: UTF-8-sig
```

---

# 3. 데이터 전처리 및 변환

## 3.1 데이터 병합

### 3.1.1 병합 전 데이터 상태

**aladin.csv (1차 크롤링):**
```
총 행 수: 3,539개
고유 도서: 1,960개
결측치: 없음

특징:
- 같은 도서가 여러 달 베스트셀러에 진입한 경우 여러 행으로 기록
- category: "국내도서" 등 포괄적 카테고리
- page_count: 모두 0 (정보 없음)
```

**detail_mapping.csv (2차 크롤링):**
```
총 행 수: 1,958개 (고유 도서)
결측치:
- detail_category: 21개 (1.1%)
- page_count: 0개 (모두 값 존재, 단 21개가 0)

특징:
- item_id 기준 1:1 매칭
- detail_category: "소설/시/희곡" 등 구체적 카테고리
- page_count: 0인 경우 = 성인 도서 (접근 불가)
```

### 3.1.2 병합 과정

**병합 전 결측치:**
```
detail_mapping.csv:
- item_id: 0개
- detail_category: 21개 (1.1%) ← 성인 도서
- page_count: 0개
```

**병합 실행:**
- LEFT JOIN (item_id 기준)
- 1차 크롤링 데이터에 2차 크롤링 데이터 병합
- 결과: 3,539개 행

**병합 후 결측치:**
```
detail_category: 22개 (0.6%) ← 21개 고유 도서가 22회 진입
```

**22개 vs 21개 차이 원인:**
- **21개**: 고유 도서 개수 (detail_mapping.csv 기준)
- **22개**: 베스트셀러 진입 횟수 (aladin.csv 기준)
- 성인 도서 중 1개가 **2번 베스트셀러에 진입**

## 3.2 카테고리 정제

### 3.2.1 카테고리 업데이트

**업데이트 결과:**
```
카테고리 업데이트 성공: 3,517개 (99.4%)
카테고리 업데이트 실패: 22개 (0.6%)

업데이트 실패 사유: 성인 도서 (detail_category = NaN)
```

### 3.2.2 Before / After 비교

| item_id | category (Before) | detail_category | category (After) |
|---------|-------------------|-----------------|------------------|
| 123456 | 국내도서 | 소설/시/희곡 | 소설/시/희곡 ✅ |
| 234567 | 국내도서 | 인문학 | 인문학 ✅ |
| 345678 | 국내도서 | NaN | 국내도서 ❌ (성인) |

### 3.2.3 최종 카테고리 분포
```
소설/시/희곡     742개
만화           453개
인문학         335개
경제경영       314개
어린이         289개
자기계발       244개
에세이         189개
외국어         172개
역사           148개
과학           127개
```

## 3.3 결측치 처리

### 3.3.1 페이지 수 업데이트
```
page_count = 0인 도서: 22개 (0.6%)
```

### 3.3.2 제거 대상 분석

성인 도서는 **page_count = 0 AND detail_category = NaN** 조건으로 식별합니다.
```
제거 대상:
- 행 수: 22회 (베스트셀러 진입 기준)
- 고유 도서: 21개
- 이유: 성인 도서 (상세 페이지 접근 불가)

도서별 진입 횟수:
- 21개 고유 도서가 총 22회 베스트셀러에 진입
- 이 중 1개 도서가 2번 진입
```

### 3.3.3 데이터 정제
```
최종 데이터:
- 병합 후: 3,539개 행
- 제거: 22개 행
- 최종: 3,517개 행
```

## 3.4 데이터 검증

### 3.4.1 이상치 탐지

**가격 분석:**
```
평균: 15,296원
최소: 0원 (무료 전자책)
최대: 398,000원 (고가 전집)
```

**페이지 수 분석:**
```
평균: 334쪽
최소: 16쪽 (그림책)
최대: 2,968쪽 (전집)
```

**이상치 판단:**
- 모든 이상치가 실제 도서 특성을 반영 → 제거 불필요

### 3.4.2 중복 데이터 확인
```
완전 중복 행: 0개 ✅
item_id + year + month 중복: 0개 ✅
```

## 3.5 최종 데이터 구조

### 3.5.1 컬럼 정보

| 컬럼명 | 데이터 타입 | 설명 | 결측치 | 예시 |
|--------|-------------|------|--------|------|
| year | int64 | 연도 | 0 | 2024 |
| month | int64 | 월 | 0 | 10 |
| rank | int64 | 순위 (1~50) | 0 | 1 |
| title | object | 도서명 | 0 | 소년이 온다 |
| author | object | 저자명 | 0 | 한강 |
| category | object | 카테고리 (21개) | 0 | 소설/시/희곡 |
| price | int64 | 가격 (원) | 0 | 14,220 |
| star_score | float64 | 평점 (0~10) | 0 | 9.2 |
| item_id | object | 도서 고유 ID | 0 | 8936433660 |
| page_count | int64 | 페이지 수 | 0 | 216 |

### 3.5.2 최종 통계
```
총 행 수: 3,517개
고유 도서: 1,939개
기간: 2020년 1월 ~ 2025년 11월
카테고리: 21개
평균 가격: 15,296원
평균 페이지: 334쪽
평균 평점: 9.05점
```

## 3.6 전처리 흐름도
```
┌─────────────────────────────────────┐
│   원본 데이터                        │
│   - aladin.csv: 3,539개             │
│   - detail_mapping.csv: 1,958개     │
└─────────────┬───────────────────────┘
              ↓
┌─────────────────────────────────────┐
│   1. 데이터 병합                     │
│   - LEFT JOIN (item_id 기준)        │
│   - 결과: 3,539개 행                │
└─────────────┬───────────────────────┘
              ↓
┌─────────────────────────────────────┐
│   2. 카테고리 업데이트               │
│   - detail_category → category      │
│   - 성공: 3,517개 (99.4%)           │
│   - 실패: 22개 (0.6%, 성인 도서)    │
└─────────────┬───────────────────────┘
              ↓
┌─────────────────────────────────────┐
│   3. 페이지 수 업데이트              │
│   - page_count_new → page_count     │
│   - page_count = 0: 22개            │
└─────────────┬───────────────────────┘
              ↓
┌─────────────────────────────────────┐
│   4. 성인 도서 제거                  │
│   - 조건: page_count=0 AND          │
│          detail_category=NaN        │
│   - 제거: 22개 행 (21개 고유 도서)  │
└─────────────┬───────────────────────┘
              ↓
┌─────────────────────────────────────┐
│   5. 데이터 검증                     │
│   - 이상치 확인                      │
│   - 데이터 타입 통일                 │
│   - 중복 데이터 확인                 │
└─────────────┬───────────────────────┘
              ↓
┌─────────────────────────────────────┐
│   최종 데이터                        │
│   - 3,517개 행                      │
│   - 1,939개 고유 도서               │
│   - 21개 카테고리                   │
│   - 결측치: 0개                     │
└─────────────────────────────────────┘
```

---

# 4. 핵심 분석 결과

## 4.1 2022년 가격·페이지 수 하락 분석

### 4.1.1 현상 확인

**연도별 평균 가격 추이:**
```
2020년: 14,481원
2021년: 15,386원 (+6.2%)
2022년: 14,481원 (-5.9%) ← 급락
2023년: 15,348원 (+6.0%)
2024년: 16,010원 (+4.3%)
2025년: 16,155원 (+0.9%)
```

**연도별 평균 페이지 수 추이:**
```
2020년: 325쪽
2021년: 365쪽 (+12.3%)
2022년: 314쪽 (-14.0%) ← 급락
2023년: 342쪽 (+8.9%)
2024년: 333쪽 (-2.6%)
2025년: 328쪽 (-1.5%)
```

### 4.1.2 원인 분석: 3중 구조

**1️⃣ 일반 도서 자체 하락 (가장 큰 원인)**
```
만화/어린이 제외 일반 도서:
- 가격: 16,541원 → 16,006원 (-3.2%)
- 페이지: 412쪽 → 355쪽 (-13.8%) ← 주된 요인
- 400쪽 이상 두꺼운 책: 158개 → 114개 (-7.6%p)
```

**2️⃣ 저가·저페이지 장르 비중 증가**
```
만화·어린이 비중:
- 2021년: 138개 (23.2%)
- 2022년: 154개 (25.7%) ← +2.5%p
- 만화 평균 가격: 약 10,075원 (일반 도서의 63%)
- 만화 평균 페이지: 약 197쪽 (일반 도서의 56%)
```

**3️⃣ 카테고리 구조 변화**
```
고가 카테고리 급감:
- 경제경영: 72회 → 47회 (-34.7%)
- 에세이: 59회 → 31회 (-47.5%)
- 사회과학: 21회 → 0회 (-100%)

저가 카테고리 증가:
- 만화: 72회 → 90회 (+25.0%)
- 자기계발: 21회 → 45회 (+114.3%)
```

**종합 효과:**
```
전체 평균에 이중 효과:
- 가격: -5.9% = (일반 -3.2%) + (장르 구성 -2.7%p)
- 페이지: -14.0% = (일반 -13.8%) + (장르 구성 -0.2%p)
```

### 4.1.3 핵심 인사이트

베스트셀러 평균 지표는 **장르 구성에 매우 민감하게 반응**함을 실증적으로 확인했습니다. 2022년 하락은 일반 도서 자체의 변화와 장르 구성 변화가 복합적으로 작용한 결과로 해석됩니다.

---

## 4.2 한강 노벨문학상 효과

### 4.2.1 수상 전후 비교

**베스트셀러 진입 횟수:**
```
수상 전 (2020.1~2024.9, 57개월): 7회
수상 후 (2024.10~2025.11, 14개월): 60회
증가율: +757% (약 8.6배)
```

### 4.2.2 시장 점유율 변화

**소설 시장 내 점유율:**
```
수상 전 평균: 0.5%
수상 후 평균: 7.2%
증가: +6.7%p (14.4배)

월별 최고점: 2024년 10월 17.3%
```

### 4.2.3 핵심 인사이트

노벨문학상 수상이라는 외부 이벤트가 베스트셀러 시장에 미치는 영향을 정량적으로 확인했습니다. 수상 후 14개월간 평균 점유율이 14.4배 증가하며, 2024년 10월에는 소설 시장의 17.3%를 차지했습니다.

---

## 4.3 슬램덩크 영화 개봉 효과

### 4.3.1 연도별 진입 횟수

**슬램덩크 관련 도서 진입 횟수:**
```
2020년: 0회
2021년: 0회
2022년: 0회
2023년: 53회 ← 영화 개봉 (2023.01.04)
2024년: 1회
2025년: 0회
```

### 4.3.2 만화 비중 변화

**만화 카테고리 비중:**
```
2020년: 17%
2021년: 21%
2022년: 25%
2023년: 32% ← 정점 (슬램덩크 46% 기여)
2024년: 20%
2025년: 15%
```

### 4.3.3 핵심 인사이트

영화 흥행(490만 관객, 일본 아카데미상)과 원작 만화 판매 증가 간 강한 상관관계가 관찰되었습니다. 슬램덩크 단일 시리즈가 2023년 만화 카테고리 베스트셀러 진입의 46%를 차지하며, 문화 콘텐츠 간 시너지 효과를 확인했습니다.

---

## 4.4 카테고리 비중 변화 (5년 트렌드)

**만화:**
```
2020년: 17% → 2023년: 32% (정점) → 2025년: 15%
변화: +15%p → -17%p
```

**인문학:**
```
2020년: 8% → 2025년: 23%
변화: +15%p (약 3배 증가)
```

**경제경영:**
```
2020년: 18% → 2021년: 20% (정점) → 2025년: 8%
변화: +2%p → -12%p
```

---

# 5. 결론

본 프로젝트는 2020~2025년 알라딘 월간 베스트셀러 3,517개를 크롤링·분석하여 다음을 확인했습니다.

## 핵심 발견

**1. 외부 문화 이벤트의 강력한 시장 영향력**

본 연구를 통해 **예측 불가능한 외부 문화적 사건이 베스트셀러 시장에 즉각적이고 강력한 영향을 미친다**는 것을 실증적으로 확인했습니다.

- **한강 노벨문학상 효과:** 수상 후 베스트셀러 진입 8.6배 증가 (7회→60회), 소설 시장 점유율 14.4배 증가 (0.5%→7.2%)
- **슬램덩크 영화 개봉 효과:** 원작 만화 53회 진입 (2022년 0회), 만화 비중 정점 달성 (32%)

이는 **문화 콘텐츠 간 시너지 효과**가 출판 시장에서 매우 강하게 작용하며, 영화·수상과 같은 외부 이벤트가 단기간에 시장 구조를 변화시킬 수 있음을 보여줍니다. 특히 이러한 효과는 AI 예측 모델이 포착하지 못한 영역으로, **실시간 데이터 모니터링의 필요성**을 시사합니다.

**2. 베스트셀러 지표의 구조적 특성**

- **2022년 가격·페이지 하락:** 일반 도서 자체 하락 + 저가 장르 비중 증가의 이중 구조 확인
- **핵심 발견:** 베스트셀러 평균 지표는 **장르 구성 변화에 매우 민감하게 반응**함을 실증

이는 베스트셀러 평균 가격/페이지가 "출판 시장 전체"를 대표하지 않으며, **특정 장르의 일시적 유행에 크게 영향받는다**는 것을 의미합니다. 따라서 시장 분석 시 장르별 분해 분석이 필수적입니다.

**3. 장기적 독서 트렌드의 변화**

- **인문학 약 3배 성장:** 2020년 8% → 2025년 23%
- **경제경영 감소:** 2021년 20% → 2025년 8%

5년간의 데이터를 통해 **단순 정보 소비에서 성찰적 독서로의 전환**이라는 장기 트렌드를 확인했습니다. 이는 외부 이벤트의 단기 충격과 대비되는 구조적·점진적 변화입니다.

---

## 연구의 의의

**1. 방법론적 기여**

- **외부 이벤트의 정량적 측정:** 노벨상 수상, 영화 개봉 등 문화적 사건이 출판 시장에 미치는 영향을 정량화하는 방법론 제시
- **장르 분해 분석:** 평균 지표의 한계를 보완하는 장르별 분석의 중요성 실증
- **실증 vs 예측 비교:** AI 예측 모델의 한계를 데이터로 검증

**2. 실무적 활용**

- **출판 기획:** 외부 이벤트(영화 개봉, 수상 등)와 연계한 출판 전략 수립 가능
- **재고 관리:** 문화 이벤트 발생 시 신속한 재고 확보 및 마케팅 대응
- **트렌드 예측:** 장르별 장기 트렌드와 단기 이벤트 효과를 구분한 전략 수립

**3. 학술적 기여**

본 분석은 베스트셀러 시장의 변화를 설명하는 데 그치지 않고, **문화경제학·독서사회학 연구에서도 활용 가능한 정량적 근거를 제공**합니다. 특히 **외부 문화적 사건이 출판 시장에 미치는 영향의 규모와 지속 기간을 실증적으로 분석**함으로써, 문화 콘텐츠 간 시너지 효과를 정량화하는 방법론적 기여를 할 수 있습니다.

---

## 연구의 한계 및 향후 과제

**1. 데이터 범위의 한계**
- 알라딘 단일 플랫폼만 분석 (교보문고, YES24 등 미포함)
- 베스트셀러 중심 분석으로 전체 출판 시장과 차이 가능

**2. 인과관계 검증의 한계**
- 외부 이벤트와 판매 증가 간 강한 상관관계 확인
- 직접적 인과관계 입증을 위해서는 추가 연구 필요 (언론 보도량, SNS 확산, 독자 구매 동기 등)

**3. 향후 연구 방향**
- 다중 플랫폼 데이터 통합 분석
- 독자 설문조사를 통한 정성적 데이터 수집
- 실시간 모니터링 시스템 구축

---

## 최종 결론

본 연구는 **외부 문화적 이벤트가 베스트셀러 시장에 미치는 영향을 실증적으로 정량화**했습니다. 한강 노벨문학상(8.6배 증가)과 슬램덩크 영화 개봉(53회 진입)은 **예측 불가능한 외부 요인이 단기간에 시장 구조를 변화시킬 수 있음**을 명확히 보여줍니다.

동시에 인문학의 3배 성장과 같은 **장기적 트렌드의 존재**도 확인했으며, 이는 외부 충격과 구별되는 독자 선호의 구조적 변화를 의미합니다.

출판 시장 분석에서는 (1) 외부 이벤트의 단기 충격, (2) 장르 구성 변화의 영향, (3) 장기적 독서 트렌드를 **종합적으로 고려해야** 정확한 시장 이해가 가능합니다. 본 연구는 이러한 다층적 분석의 필요성을 실증적으로 제시했습니다.

---

## 기술적 성과

- BeautifulSoup4 기반 71개월 자동 크롤링 구현 (3,539개 수집)
- 병렬 처리를 통한 1,958개 도서 상세 정보 수집
- 성인 도서·결측치 처리 등 체계적 전처리 수행 (최종 3,517개)
- 장르 구성 변화가 평균 지표에 미치는 영향 정량화

---

## GitHub Repository

**프로젝트 전체 코드 및 데이터:**  
https://github.com/username/aladin-project

**포함 내용:**
- 크롤링 코드 (1차, 2차)
- 전처리 코드
- 시각화 코드 (15개 메인 + 4개 검증)
- 최종 데이터 (aladin_final_cleaned.csv)
- 상세 문서 (README.md)

---

## 참고문헌

1. 알라딘, 월간 베스트셀러 TOP 50 (2020.01~2025.11)
   - https://www.aladin.co.kr/shop/common/wbest.aspx

2. 대한출판문화협회(2023.07.17). 『2022년 책 종수와 평균 정가』 통계 발표

---
